{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "ir",
      "display_name": "R"
    },
    "language_info": {
      "name": "R"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/epare2496-commits/labo2025v/blob/main/src/ensembles/594_61_TareaHogar_05.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tarea para el Hogar 05"
      ],
      "metadata": {
        "id": "0cEmzeUKFkPh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esta Tarea para el Hogar 05 se entrega el final de la cuarta clase\n",
        "<br> se espera de usted que intente avanzar con los desafios propuestos y que los traiga terminados para la Clase 05 que será el miercoles 03 de septiembre"
      ],
      "metadata": {
        "id": "nSICPpyTGQmC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  1. Overfitting the Public Leaderboard"
      ],
      "metadata": {
        "id": "DenyKXkiJ5JN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Leer  https://medium.com/hmif-itb/overfitting-the-leaderboard-da25172ac62e\n",
        "( 8 minutos )"
      ],
      "metadata": {
        "id": "l-K2_ZsZGrVD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Hiperparámetros del LightGBM"
      ],
      "metadata": {
        "id": "K9GkTOk5J9t3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Los objetivos de esta tarea son:\n",
        "\n",
        "\n",
        "*   Aumentar la rentabilidad de la campaña de marketing de retención proactiva de clientes.\n",
        "*   Generar un mejor modelo optimizando sus hiperparámetros\n",
        "*   Conceptual : investigar los mas relevantes hiperparámetros de LightGBM\n",
        "*   Familiarizarse con la Bayesian Optimization, sus largos tiempos de corrida y opciones para reducirlos\n",
        "*   Familiarizarse con el uso de máquinas virtuales de Google Colab\n",
        "*   Ver un pipeline completo de optimización de hiperparámetros y puesta en producción"
      ],
      "metadata": {
        "id": "VmEFy0ukKL5T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "LightGBM cuenta con mas de 60 hiperparámetros, siendo posible utilizar 40 al mismo tiempo, aunque no razonable.\n",
        "<br> La documentación oficial de los hiperparámetros de LightGBM es  https://lightgbm.readthedocs.io/en/latest/Parameters.html#core-parameters\n"
      ],
      "metadata": {
        "id": "5yvlS6JQLRMd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se lo alerta sobre que una Optimizacion Bayesiana lleva varias horas de corrida, y usted deberá correr VARIAS optimizaciones para descubrir cuales parámetros conviene optimizar.\n",
        "<br> A pesar que la próxima clase es recien en viernes 01 de agosto, inicie la tarea con tiempo, aprenda a planificar estratégicamente sus corridas como un@ científ@  de datos."
      ],
      "metadata": {
        "id": "eydI4YNAsFaf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Es necesario investigar cuales son los hiperparámetros de LightGBM que vale la pena optimizar en una Bayesian Optimization, ya que los realmente utiles son apenas un reducido subconjunto.\n",
        "<br>Usted deberá investigar cuales son los hiperparámetros mas relevantes de LightGBM, su primer alternativa es preguntándole a su amigo con capacidades especiales ChatGPT o sus endogámicos familiares Claude, DeepSeek, Gemini, Grok, etc\n",
        "<br> La segunda alternativa es la propia documentación de LightGBM  https://lightgbm.readthedocs.io/en/latest/Parameters-Tuning.html\n"
      ],
      "metadata": {
        "id": "RzU4S0SeMcpp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adicionalmente podra buscar información como la que proveen esta diminuta muestra aleatoria de artículos ligeros:\n",
        "* https://machinelearningmastery.com/light-gradient-boosted-machine-lightgbm-ensemble/\n",
        "*  https://medium.com/@sarahzouinina/a-deep-dive-into-lightgbm-how-to-choose-and-tune-parameters-7c584945842e\n",
        "*  https://www.kaggle.com/code/somang1418/tuning-hyperparameters-under-10-minutes-lgbm\n",
        "*  https://towardsdatascience.com/beginners-guide-to-the-must-know-lightgbm-hyperparameters-a0005a812702/\n",
        "\n",
        "\n",
        "<br>  La muestra anterior se brinda a modo de ejemplo, usted deberá buscar muuuuchas  fuentes adicionales de información\n",
        "<br> Tenga presente que LightGBM es el estado del arte en modelado predictivo para datasets estructurado, que son el 90% del trabajo del 95% de los Data Scientists en Argentina."
      ],
      "metadata": {
        "id": "LNptUgI_NWWG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El desafío de esta tarea es:\n",
        "* Qué hiperparparámetros conviene optimizar?  Las recomendaciones de los artículos ligeros es siempre sensata?  Sus autores realmente hicieron experimentos o son siemplemente escritores de entretenimiento carente de base científica?\n",
        "* Elegidos los hiperparámetros, cual es el  <desde, hasta> que se debe utilizar en la Bayesian Optimization ?\n",
        "* Realmente vale la pena optimizar 10 o 16 hiperparámetros al mismo tiempo ?  No resulta contraproducente una búsqueda en un espacio de tal alta dimensionalidad ?"
      ],
      "metadata": {
        "id": "WpUThBojODyK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.1  Seteo del ambiente en Google Colab"
      ],
      "metadata": {
        "id": "PX0qg_c0yqob"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGY7H9xza7Zr"
      },
      "source": [
        "Esta parte se debe correr con el runtime en Python3\n",
        "<br>Ir al menu, Runtime -> Change Runtime Type -> Runtime type ->  **Python 3**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7PupIBNba7Zr"
      },
      "source": [
        "Conectar la virtual machine donde esta corriendo Google Colab con el  Google Drive, para poder tener persistencia de archivos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "9LpZCst5a7Zs",
        "outputId": "c8b9ade6-dc9f-4899-9b7e-0a763f9c83b7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/.drive\n"
          ]
        }
      ],
      "source": [
        "# primero establecer el Runtime de Python 3\n",
        "from google.colab import drive\n",
        "drive.mount('/content/.drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JYC_F-wla7Zs"
      },
      "source": [
        "Para correr la siguiente celda es fundamental en Arranque en Frio haber copiado el archivo kaggle.json al Google Drive, en la carpeta indicada en el instructivo\n",
        "\n",
        "<br>los siguientes comando estan en shell script de Linux\n",
        "*   Crear las carpetas en el Google Drive\n",
        "*   \"instalar\" el archivo kaggle.json desde el Google Drive a la virtual machine para que pueda ser utilizado por la libreria  kaggle de Python\n",
        "*   Bajar el  **dataset_pequeno**  al  Google Drive  y tambien al disco local de la virtual machine que esta corriendo Google Colab\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "XWLelftXa7Zt",
        "outputId": "f3433e96-5abd-41f4-ebe3-d3f11cd8673d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "%%shell\n",
        "\n",
        "mkdir -p \"/content/.drive/My Drive/labo1\"\n",
        "mkdir -p \"/content/buckets\"\n",
        "ln -s \"/content/.drive/My Drive/labo1\" /content/buckets/b1\n",
        "\n",
        "mkdir -p ~/.kaggle\n",
        "cp /content/buckets/b1/kaggle/kaggle.json  ~/.kaggle\n",
        "chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "\n",
        "mkdir -p /content/buckets/b1/exp\n",
        "mkdir -p /content/buckets/b1/datasets\n",
        "mkdir -p /content/datasets\n",
        "\n",
        "\n",
        "\n",
        "archivo_origen=\"https://storage.googleapis.com/open-courses/austral2025-af91/dataset_pequeno.csv\"\n",
        "archivo_destino=\"/content/datasets/dataset_pequeno.csv\"\n",
        "archivo_destino_bucket=\"/content/buckets/b1/datasets/dataset_pequeno.csv\"\n",
        "\n",
        "if ! test -f $archivo_destino_bucket; then\n",
        "  wget  $archivo_origen  -O $archivo_destino_bucket\n",
        "fi\n",
        "\n",
        "\n",
        "if ! test -f $archivo_destino; then\n",
        "  cp  $archivo_destino_bucket  $archivo_destino\n",
        "fi\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2 Optimizacion Hiperparámetros"
      ],
      "metadata": {
        "id": "oSKhZRToy2F7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esta parte se debe correr con el runtime en lenguaje R Ir al menu, Runtime -> Change Runtime Type -> Runtime type -> R"
      ],
      "metadata": {
        "id": "2kwPpHAtSmix"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2.1 Inicio"
      ],
      "metadata": {
        "id": "xp4-Bj3aYI8d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "limpio el ambiente de R"
      ],
      "metadata": {
        "id": "zy8YTZfESxeJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "format(Sys.time(), \"%a %b %d %X %Y\")"
      ],
      "metadata": {
        "id": "gBq__iAdQliq",
        "outputId": "7cb716b8-3c92-420e-f604-10e5a53c4314",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "'Tue Nov 04 12:03:33 PM 2025'"
            ],
            "text/markdown": "'Tue Nov 04 12:03:33 PM 2025'",
            "text/latex": "'Tue Nov 04 12:03:33 PM 2025'",
            "text/plain": [
              "[1] \"Tue Nov 04 12:03:33 PM 2025\""
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# limpio la memoria\n",
        "rm(list=ls(all.names=TRUE)) # remove all objects\n",
        "gc(full=TRUE, verbose=FALSE) # garbage collection"
      ],
      "metadata": {
        "id": "7rdVrBojS1IV",
        "outputId": "0fc2c3ea-6417-4c97-86e9-c0072ea998ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table class=\"dataframe\">\n",
              "<caption>A matrix: 2 × 6 of type dbl</caption>\n",
              "<thead>\n",
              "\t<tr><th></th><th scope=col>used</th><th scope=col>(Mb)</th><th scope=col>gc trigger</th><th scope=col>(Mb)</th><th scope=col>max used</th><th scope=col>(Mb)</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "\t<tr><th scope=row>Ncells</th><td> 660468</td><td>35.3</td><td>1454460</td><td>77.7</td><td>1438471</td><td>76.9</td></tr>\n",
              "\t<tr><th scope=row>Vcells</th><td>1226772</td><td> 9.4</td><td>8388608</td><td>64.0</td><td>1975128</td><td>15.1</td></tr>\n",
              "</tbody>\n",
              "</table>\n"
            ],
            "text/markdown": "\nA matrix: 2 × 6 of type dbl\n\n| <!--/--> | used | (Mb) | gc trigger | (Mb) | max used | (Mb) |\n|---|---|---|---|---|---|---|\n| Ncells |  660468 | 35.3 | 1454460 | 77.7 | 1438471 | 76.9 |\n| Vcells | 1226772 |  9.4 | 8388608 | 64.0 | 1975128 | 15.1 |\n\n",
            "text/latex": "A matrix: 2 × 6 of type dbl\n\\begin{tabular}{r|llllll}\n  & used & (Mb) & gc trigger & (Mb) & max used & (Mb)\\\\\n\\hline\n\tNcells &  660468 & 35.3 & 1454460 & 77.7 & 1438471 & 76.9\\\\\n\tVcells & 1226772 &  9.4 & 8388608 & 64.0 & 1975128 & 15.1\\\\\n\\end{tabular}\n",
            "text/plain": [
              "       used    (Mb) gc trigger (Mb) max used (Mb)\n",
              "Ncells  660468 35.3 1454460    77.7 1438471  76.9\n",
              "Vcells 1226772  9.4 8388608    64.0 1975128  15.1"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2.2 Carga de Librerias"
      ],
      "metadata": {
        "id": "kuPfQ7ksjwW3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# cargo las librerias que necesito\n",
        "require(\"data.table\")\n",
        "require(\"parallel\")\n",
        "\n",
        "if( !require(\"primes\") ) install.packages(\"primes\")\n",
        "require(\"primes\")\n",
        "\n",
        "if( !require(\"utils\") ) install.packages(\"utils\")\n",
        "require(\"utils\")\n",
        "\n",
        "if( !require(\"rlist\") ) install.packages(\"rlist\")\n",
        "require(\"rlist\")\n",
        "\n",
        "if( !require(\"yaml\")) install.packages(\"yaml\")\n",
        "require(\"yaml\")\n",
        "\n",
        "if( !require(\"lightgbm\") ) install.packages(\"lightgbm\")\n",
        "require(\"lightgbm\")\n",
        "\n",
        "if( !require(\"DiceKriging\") ) install.packages(\"DiceKriging\")\n",
        "require(\"DiceKriging\")\n",
        "\n",
        "if( !require(\"mlrMBO\") ) install.packages(\"mlrMBO\")\n",
        "require(\"mlrMBO\")"
      ],
      "metadata": {
        "id": "lVyxLaJ1j1J_",
        "outputId": "eeda3737-5df6-4f75-9b1c-df336ac7edab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading required package: data.table\n",
            "\n",
            "Loading required package: parallel\n",
            "\n",
            "Loading required package: primes\n",
            "\n",
            "Warning message in library(package, lib.loc = lib.loc, character.only = TRUE, logical.return = TRUE, :\n",
            "“there is no package called ‘primes’”\n",
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "Loading required package: primes\n",
            "\n",
            "Loading required package: rlist\n",
            "\n",
            "Warning message in library(package, lib.loc = lib.loc, character.only = TRUE, logical.return = TRUE, :\n",
            "“there is no package called ‘rlist’”\n",
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "also installing the dependency ‘XML’\n",
            "\n",
            "\n",
            "Loading required package: rlist\n",
            "\n",
            "Loading required package: yaml\n",
            "\n",
            "Loading required package: lightgbm\n",
            "\n",
            "Warning message in library(package, lib.loc = lib.loc, character.only = TRUE, logical.return = TRUE, :\n",
            "“there is no package called ‘lightgbm’”\n",
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "Loading required package: lightgbm\n",
            "\n",
            "Loading required package: DiceKriging\n",
            "\n",
            "Warning message in library(package, lib.loc = lib.loc, character.only = TRUE, logical.return = TRUE, :\n",
            "“there is no package called ‘DiceKriging’”\n",
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "Loading required package: DiceKriging\n",
            "\n",
            "Loading required package: mlrMBO\n",
            "\n",
            "Warning message in library(package, lib.loc = lib.loc, character.only = TRUE, logical.return = TRUE, :\n",
            "“there is no package called ‘mlrMBO’”\n",
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "also installing the dependencies ‘fastmatch’, ‘RcppArmadillo’, ‘mlr’, ‘ParamHelpers’, ‘smoof’, ‘BBmisc’, ‘checkmate’, ‘lhs’, ‘parallelMap’\n",
            "\n",
            "\n",
            "Loading required package: mlrMBO\n",
            "\n",
            "Loading required package: mlr\n",
            "\n",
            "Loading required package: ParamHelpers\n",
            "\n",
            "Loading required package: smoof\n",
            "\n",
            "Loading required package: checkmate\n",
            "\n",
            "\n",
            "Attaching package: ‘checkmate’\n",
            "\n",
            "\n",
            "The following object is masked from ‘package:DiceKriging’:\n",
            "\n",
            "    checkNames\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2.3 Definicion de Parametros"
      ],
      "metadata": {
        "id": "Iz-6Qt6BUaA3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "aqui debe cargar SU semilla primigenia\n",
        "<br>recuerde cambiar el numero de experimento en cada corrida nueva"
      ],
      "metadata": {
        "id": "cOdlKd7lUm2I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PARAM <- list()\n",
        "PARAM$experimento <- 5952\n",
        "PARAM$semilla_primigenia <- 100009\n"
      ],
      "metadata": {
        "id": "ASYkebOu2mF6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PARAM$kaggle$competencia <- \"labo-i-2025-virtual-analista-sr\"\n",
        "PARAM$kaggle$cortes <- seq(10000, 12000, by= 500)"
      ],
      "metadata": {
        "id": "ezOhQdbA293o"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# un undersampling de 0.1  toma solo el 10% de los CONTINUA\n",
        "# undersampling de 1.0  implica tomar TODOS los datos\n",
        "\n",
        "PARAM$trainingstrategy$undersampling <- 0.5"
      ],
      "metadata": {
        "id": "jtB0Lub42rHO"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parametros LightGBM\n",
        "\n",
        "PARAM$hyperparametertuning$xval_folds <- 5\n",
        "\n",
        "# parametros fijos del LightGBM que se pisaran con la parte variable de la BO\n",
        "PARAM$lgbm$param_fijos <-  list(\n",
        "  boosting= \"gbdt\", # puede ir  dart  , ni pruebe random_forest\n",
        "  objective= \"binary\",\n",
        "  metric= \"auc\",\n",
        "  first_metric_only= FALSE,\n",
        "  boost_from_average= TRUE,\n",
        "  feature_pre_filter= FALSE,\n",
        "  force_row_wise= TRUE, # para reducir warnings\n",
        "  verbosity= -100,\n",
        "\n",
        "  seed= PARAM$semilla_primigenia,\n",
        "\n",
        "  max_depth= -1L, # -1 significa no limitar,  por ahora lo dejo fijo\n",
        "  min_gain_to_split= 0, # min_gain_to_split >= 0\n",
        "  min_sum_hessian_in_leaf= 0.001, #  min_sum_hessian_in_leaf >= 0.0\n",
        "  lambda_l1= 0.0, # lambda_l1 >= 0.0\n",
        "  lambda_l2= 0.0, # lambda_l2 >= 0.0\n",
        "  max_bin= 31L, # lo debo dejar fijo, no participa de la BO\n",
        "\n",
        "  bagging_fraction= 0.5, # 0.0 < bagging_fraction <= 1.0\n",
        "  pos_bagging_fraction= 1.0, # 0.0 < pos_bagging_fraction <= 1.0\n",
        "  neg_bagging_fraction= 1.0, # 0.0 < neg_bagging_fraction <= 1.0\n",
        "  bagging_freq = 10,\n",
        "  is_unbalance= FALSE, #\n",
        "  scale_pos_weight= 1.0, # scale_pos_weight > 0.0\n",
        "\n",
        "  drop_rate= 0.1,      # 0.0 < neg_bagging_fraction <= 1.0\n",
        "  max_drop= 50,        # <=0 means no limit\n",
        "  skip_drop= 0.5,      # 0.0 <= skip_drop <= 1.0\n",
        "\n",
        "  extra_trees= FALSE,\n",
        "\n",
        "  num_iterations= 3500, #aumento porque pongo el stopping, tenia 1200\n",
        "  early_stopping_rounds= 200,  #agregue jwb\n",
        "  learning_rate= 0.02,\n",
        "  feature_fraction= 0.5,\n",
        "  num_leaves= 750,\n",
        "  min_data_in_leaf= 5000\n",
        ")\n"
      ],
      "metadata": {
        "id": "OFxm-xiNUOJX"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aqui se definen los hiperparámetros de LightGBM que participan de la Bayesian Optimization\n",
        "<br> si es un numero entero debe ir  makeIntegerParam\n",
        "<br> si es un numero real (con decimales) debe ir  makeNumericParam\n",
        "<br> es muy importante leer cuales son un lower y upper  permitidos y ademas razonables"
      ],
      "metadata": {
        "id": "D5Yj-JV4yvOt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Aqui se cargan los bordes de los hiperparametros de la BO\n",
        "PARAM$hypeparametertuning$hs <- makeParamSet(\n",
        "  # makeIntegerParam(\"num_iterations\", lower= 8L, upper= 2048L),\n",
        "  makeNumericParam(\"learning_rate\", lower= 0.01, upper= 0.3),\n",
        "  makeNumericParam(\"feature_fraction\", lower= 0.4, upper= 0.6), # cambie segun experiencia clase 5\n",
        "  makeIntegerParam(\"num_leaves\", lower= 8L, upper= 2048L),\n",
        "  makeIntegerParam(\"min_data_in_leaf\", lower= 1L, upper= 8000L),\n",
        "  makeNumericParam(\"bagging_fraction\", lower=0.3, upper= 0.7)\n",
        ")"
      ],
      "metadata": {
        "id": "jENpR26ZyuS8"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A mayor cantidad de hiperparámetros, se debe aumentar las iteraciones de la Bayesian Optimization\n",
        "<br> 30 es un valor muy tacaño, pero corre rápido\n",
        "<br> deberia partir de 50, alcanzando los 100 si se dispone de tiempo"
      ],
      "metadata": {
        "id": "-_RPFUb3zMoW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PARAM$hyperparametertuning$iteraciones <- 100 # iteraciones bayesianas"
      ],
      "metadata": {
        "id": "q5Rd3pnbzSiG"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2.4  Preprocesamiento"
      ],
      "metadata": {
        "id": "4RWZXL1VZjMI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# carpeta de trabajo\n",
        "\n",
        "setwd(\"/content/buckets/b1/exp\")\n",
        "experimento_folder <- paste0(\"HT\", PARAM$experimento)\n",
        "dir.create(experimento_folder, showWarnings=FALSE)\n",
        "setwd( paste0(\"/content/buckets/b1/exp/\", experimento_folder ))"
      ],
      "metadata": {
        "id": "j3toG9-lZm4K"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# lectura del dataset\n",
        "\n",
        "dataset <- fread(\"/content/datasets/dataset_pequeno.csv\")"
      ],
      "metadata": {
        "id": "FM3lxKoLZ643"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_train <- dataset[foto_mes %in% c(202107)]"
      ],
      "metadata": {
        "id": "OsJ-91UeZ-I_"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# paso la clase a binaria que tome valores {0,1}  enteros\n",
        "#  BAJA+1 y BAJA+2  son  1,   CONTINUA es 0\n",
        "\n",
        "dataset_train[,\n",
        "  clase01 := ifelse(clase_ternaria %in% c(\"BAJA+2\",\"BAJA+1\"), 1L, 0L)\n",
        "]"
      ],
      "metadata": {
        "id": "vrWE7BE0aB2J"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# defino los datos que forma parte del training\n",
        "# aqui se hace el undersampling de los CONTINUA\n",
        "# notar que para esto utilizo la SEGUNDA semilla\n",
        "\n",
        "set.seed(PARAM$semilla_primigenia, kind = \"L'Ecuyer-CMRG\")\n",
        "dataset_train[, azar := runif(nrow(dataset_train))]\n",
        "dataset_train[, training := 0L]\n",
        "\n",
        "dataset_train[\n",
        "  foto_mes %in% c(202107) &\n",
        "    (azar <= PARAM$trainingstrategy$undersampling | clase_ternaria %in% c(\"BAJA+1\", \"BAJA+2\")),\n",
        "  training := 1L\n",
        "]"
      ],
      "metadata": {
        "id": "jP7YlQBnaW6W"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# los campos que se van a utilizar\n",
        "\n",
        "campos_buenos <- setdiff(\n",
        "  colnames(dataset_train),\n",
        "  c(\"clase_ternaria\", \"clase01\", \"azar\", \"training\")\n",
        ")"
      ],
      "metadata": {
        "id": "xElu4s5W4rX7"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dejo los datos en el formato que necesita LightGBM\n",
        "\n",
        "dtrain <- lgb.Dataset(\n",
        "  data= data.matrix(dataset_train[training == 1L, campos_buenos, with= FALSE]),\n",
        "  label= dataset_train[training == 1L, clase01],\n",
        "  free_raw_data= FALSE\n",
        ")\n",
        "\n",
        "nrow(dtrain)\n",
        "ncol(dtrain)"
      ],
      "metadata": {
        "id": "PppMHcGYaaol",
        "outputId": "705b5d9a-284f-4d85-f006-d86ca37ce7d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "83297"
            ],
            "text/markdown": "83297",
            "text/latex": "83297",
            "text/plain": [
              "[1] 83297"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "154"
            ],
            "text/markdown": "154",
            "text/latex": "154",
            "text/plain": [
              "[1] 154"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.2.5 Configuracion Bayesian Optimization"
      ],
      "metadata": {
        "id": "Ta-EkOu3cphF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# En el argumento x llegan los parmaetros de la bayesiana\n",
        "#  devuelve la AUC en cross validation del modelo entrenado\n",
        "\n",
        "EstimarGanancia_AUC_lightgbm <- function(x) {\n",
        "\n",
        "  # x pisa (o agrega) a param_fijos\n",
        "  param_completo <- modifyList(PARAM$lgbm$param_fijos, x)\n",
        "\n",
        "  # entreno LightGBM\n",
        "  modelocv <- lgb.cv(\n",
        "    data= dtrain,\n",
        "    nfold= PARAM$hyperparametertuning$xval_folds,\n",
        "    stratified= TRUE,\n",
        "    param= param_completo\n",
        "  )\n",
        "\n",
        "  # obtengo la ganancia\n",
        "  AUC <- modelocv$best_score\n",
        "\n",
        "  # hago espacio en la memoria\n",
        "  rm(modelocv)\n",
        "  gc(full= TRUE, verbose= FALSE)\n",
        "\n",
        "  message(format(Sys.time(), \"%a %b %d %X %Y\"), \" AUC \", AUC)\n",
        "\n",
        "  return(AUC)\n",
        "}"
      ],
      "metadata": {
        "id": "cjgfurjdfiXb"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Aqui comienza la configuracion de la Bayesian Optimization\n",
        "\n",
        "# en este archivo quedan la evolucion binaria de la BO\n",
        "kbayesiana <- \"bayesiana.RDATA\"\n",
        "\n",
        "funcion_optimizar <- EstimarGanancia_AUC_lightgbm # la funcion que voy a maximizar\n",
        "\n",
        "configureMlr(show.learner.output= FALSE)\n",
        "\n",
        "# configuro la busqueda bayesiana,  los hiperparametros que se van a optimizar\n",
        "# por favor, no desesperarse por lo complejo\n",
        "\n",
        "obj.fun <- makeSingleObjectiveFunction(\n",
        "  fn= funcion_optimizar, # la funcion que voy a maximizar\n",
        "  minimize= FALSE, # estoy Maximizando la ganancia\n",
        "  noisy= TRUE,\n",
        "  par.set= PARAM$hypeparametertuning$hs, # definido al comienzo del programa\n",
        "  has.simple.signature= FALSE # paso los parametros en una lista\n",
        ")\n",
        "\n",
        "# cada 600 segundos guardo el resultado intermedio\n",
        "ctrl <- makeMBOControl(\n",
        "  save.on.disk.at.time= 600, # se graba cada 600 segundos\n",
        "  save.file.path= kbayesiana\n",
        ") # se graba cada 600 segundos\n",
        "\n",
        "# indico la cantidad de iteraciones que va a tener la Bayesian Optimization\n",
        "ctrl <- setMBOControlTermination(\n",
        "  ctrl,\n",
        "  iters= PARAM$hyperparametertuning$iteraciones\n",
        ") # cantidad de iteraciones\n",
        "\n",
        "# defino el método estandar para la creacion de los puntos iniciales,\n",
        "# los \"No Inteligentes\"\n",
        "ctrl <- setMBOControlInfill(ctrl, crit= makeMBOInfillCritEI())\n",
        "\n",
        "# establezco la funcion que busca el maximo\n",
        "surr.km <- makeLearner(\n",
        "  \"regr.km\",\n",
        "  predict.type= \"se\",\n",
        "  covtype= \"matern3_2\",\n",
        "  control= list(trace= TRUE)\n",
        ")\n"
      ],
      "metadata": {
        "id": "WLi_o1hocvN-"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.2.6 Corrida Bayesian Optimization"
      ],
      "metadata": {
        "id": "_uUeVo5pc4zc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# inicio la optimizacion bayesiana, retomando si ya existe\n",
        "# es la celda mas lenta de todo el notebook\n",
        "\n",
        "if (!file.exists(kbayesiana)) {\n",
        "  bayesiana_salida <- mbo(obj.fun, learner= surr.km, control= ctrl)\n",
        "} else {\n",
        "  bayesiana_salida <- mboContinue(kbayesiana) # retomo en caso que ya exista\n",
        "}"
      ],
      "metadata": {
        "id": "RcABNaKGciaz",
        "outputId": "26a07ed0-0fef-47f5-ff58-7e4209fef306",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Tue Nov 04 12:23:22 PM 2025 AUC 0.927370975508131\n",
            "\n",
            "[mbo] 6: learning_rate=0.0101; feature_fraction=0.565; num_leaves=481; min_data_in_leaf=2431; bagging_fraction=0.7 : y = 0.927 : 336.9 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 7 in the file bayesiana.RDATA.\n",
            "\n",
            "Tue Nov 04 12:29:00 PM 2025 AUC 0.927387188612326\n",
            "\n",
            "[mbo] 7: learning_rate=0.01; feature_fraction=0.435; num_leaves=480; min_data_in_leaf=2120; bagging_fraction=0.693 : y = 0.927 : 337.5 secs : infill_ei\n",
            "\n",
            "Tue Nov 04 12:34:58 PM 2025 AUC 0.926787744463162\n",
            "\n",
            "[mbo] 8: learning_rate=0.0102; feature_fraction=0.516; num_leaves=381; min_data_in_leaf=2737; bagging_fraction=0.627 : y = 0.927 : 357.4 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 9 in the file bayesiana.RDATA.\n",
            "\n",
            "Tue Nov 04 12:36:07 PM 2025 AUC 0.926578701671836\n",
            "\n",
            "[mbo] 9: learning_rate=0.112; feature_fraction=0.546; num_leaves=9; min_data_in_leaf=2592; bagging_fraction=0.7 : y = 0.927 : 68.9 secs : infill_ei\n",
            "\n",
            "Tue Nov 04 12:37:24 PM 2025 AUC 0.926588977682045\n",
            "\n",
            "[mbo] 10: learning_rate=0.0515; feature_fraction=0.4; num_leaves=19; min_data_in_leaf=2243; bagging_fraction=0.67 : y = 0.927 : 76.5 secs : infill_ei\n",
            "\n",
            "Tue Nov 04 12:43:24 PM 2025 AUC 0.926160383363393\n",
            "\n",
            "[mbo] 11: learning_rate=0.01; feature_fraction=0.476; num_leaves=509; min_data_in_leaf=3636; bagging_fraction=0.7 : y = 0.926 : 359.2 secs : infill_ei\n",
            "\n",
            "Tue Nov 04 12:46:40 PM 2025 AUC 0.928771514335357\n",
            "\n",
            "[mbo] 12: learning_rate=0.0187; feature_fraction=0.6; num_leaves=9; min_data_in_leaf=1259; bagging_fraction=0.664 : y = 0.929 : 195.4 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 13 in the file bayesiana.RDATA.\n",
            "\n",
            "Tue Nov 04 12:51:33 PM 2025 AUC 0.931209621775724\n",
            "\n",
            "[mbo] 13: learning_rate=0.0104; feature_fraction=0.579; num_leaves=10; min_data_in_leaf=82; bagging_fraction=0.7 : y = 0.931 : 293.1 secs : infill_ei\n",
            "\n",
            "Tue Nov 04 12:55:26 PM 2025 AUC 0.929781190218439\n",
            "\n",
            "[mbo] 14: learning_rate=0.0135; feature_fraction=0.544; num_leaves=16; min_data_in_leaf=1; bagging_fraction=0.699 : y = 0.93 : 231.9 secs : infill_ei\n",
            "\n",
            "Tue Nov 04 01:11:51 PM 2025 AUC 0.925866664206631\n",
            "\n",
            "[mbo] 15: learning_rate=0.0101; feature_fraction=0.592; num_leaves=1951; min_data_in_leaf=10; bagging_fraction=0.7 : y = 0.926 : 984.9 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 16 in the file bayesiana.RDATA.\n",
            "\n",
            "Tue Nov 04 01:19:14 PM 2025 AUC 0.92420990794536\n",
            "\n",
            "[mbo] 16: learning_rate=0.0108; feature_fraction=0.4; num_leaves=57; min_data_in_leaf=6811; bagging_fraction=0.7 : y = 0.924 : 442.4 secs : infill_ei\n",
            "\n",
            "Tue Nov 04 01:21:27 PM 2025 AUC 0.926812377845523\n",
            "\n",
            "[mbo] 17: learning_rate=0.0443; feature_fraction=0.588; num_leaves=8; min_data_in_leaf=3; bagging_fraction=0.7 : y = 0.927 : 132.7 secs : infill_ei\n",
            "\n",
            "Tue Nov 04 01:22:21 PM 2025 AUC 0.925273829025012\n",
            "\n",
            "[mbo] 18: learning_rate=0.179; feature_fraction=0.403; num_leaves=15; min_data_in_leaf=742; bagging_fraction=0.7 : y = 0.925 : 53.0 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 19 in the file bayesiana.RDATA.\n",
            "\n",
            "Tue Nov 04 01:23:52 PM 2025 AUC 0.925793557573628\n",
            "\n",
            "[mbo] 19: learning_rate=0.081; feature_fraction=0.4; num_leaves=1845; min_data_in_leaf=204; bagging_fraction=0.7 : y = 0.926 : 90.3 secs : infill_ei\n",
            "\n",
            "Tue Nov 04 01:24:39 PM 2025 AUC 0.924853386806264\n",
            "\n",
            "[mbo] 20: learning_rate=0.3; feature_fraction=0.518; num_leaves=10; min_data_in_leaf=2885; bagging_fraction=0.7 : y = 0.925 : 46.4 secs : infill_ei\n",
            "\n",
            "Tue Nov 04 01:25:53 PM 2025 AUC 0.926120150941664\n",
            "\n",
            "[mbo] 21: learning_rate=0.0854; feature_fraction=0.4; num_leaves=2037; min_data_in_leaf=3401; bagging_fraction=0.7 : y = 0.926 : 73.5 secs : infill_ei\n",
            "\n",
            "Tue Nov 04 01:26:28 PM 2025 AUC 0.923143552351469\n",
            "\n",
            "[mbo] 22: learning_rate=0.219; feature_fraction=0.599; num_leaves=8; min_data_in_leaf=1705; bagging_fraction=0.556 : y = 0.923 : 34.9 secs : infill_ei\n",
            "\n",
            "Tue Nov 04 01:29:14 PM 2025 AUC 0.929045806777004\n",
            "\n",
            "[mbo] 23: learning_rate=0.01; feature_fraction=0.4; num_leaves=2031; min_data_in_leaf=187; bagging_fraction=0.342 : y = 0.929 : 165.2 secs : infill_ei\n",
            "\n",
            "Tue Nov 04 01:34:24 PM 2025 AUC 0.928037132248885\n",
            "\n",
            "[mbo] 24: learning_rate=0.01; feature_fraction=0.594; num_leaves=182; min_data_in_leaf=23; bagging_fraction=0.481 : y = 0.928 : 310.2 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 25 in the file bayesiana.RDATA.\n",
            "\n",
            "Tue Nov 04 01:38:08 PM 2025 AUC 0.92854806774712\n",
            "\n",
            "[mbo] 25: learning_rate=0.0101; feature_fraction=0.401; num_leaves=1897; min_data_in_leaf=838; bagging_fraction=0.473 : y = 0.929 : 222.5 secs : infill_ei\n",
            "\n",
            "Tue Nov 04 01:38:53 PM 2025 AUC 0.924651430529576\n",
            "\n",
            "[mbo] 26: learning_rate=0.3; feature_fraction=0.587; num_leaves=2046; min_data_in_leaf=2729; bagging_fraction=0.7 : y = 0.925 : 44.5 secs : infill_ei\n",
            "\n",
            "Tue Nov 04 01:39:52 PM 2025 AUC 0.919459817013813\n",
            "\n",
            "[mbo] 27: learning_rate=0.3; feature_fraction=0.406; num_leaves=1732; min_data_in_leaf=7487; bagging_fraction=0.7 : y = 0.919 : 58.8 secs : infill_ei\n",
            "\n",
            "Tue Nov 04 01:40:49 PM 2025 AUC 0.923780458114392\n",
            "\n",
            "[mbo] 28: learning_rate=0.189; feature_fraction=0.496; num_leaves=277; min_data_in_leaf=3674; bagging_fraction=0.7 : y = 0.924 : 56.4 secs : infill_ei\n",
            "\n",
            "Tue Nov 04 01:41:42 PM 2025 AUC 0.923944969758263\n",
            "\n",
            "[mbo] 29: learning_rate=0.147; feature_fraction=0.446; num_leaves=2048; min_data_in_leaf=1615; bagging_fraction=0.678 : y = 0.924 : 52.9 secs : infill_ei\n",
            "\n",
            "Tue Nov 04 01:46:27 PM 2025 AUC 0.929923264226307\n",
            "\n",
            "[mbo] 30: learning_rate=0.0102; feature_fraction=0.4; num_leaves=9; min_data_in_leaf=4; bagging_fraction=0.397 : y = 0.93 : 283.9 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 31 in the file bayesiana.RDATA.\n",
            "\n",
            "Tue Nov 04 01:48:41 PM 2025 AUC 0.927580512295577\n",
            "\n",
            "[mbo] 31: learning_rate=0.0101; feature_fraction=0.4; num_leaves=387; min_data_in_leaf=638; bagging_fraction=0.302 : y = 0.928 : 133.1 secs : infill_ei\n",
            "\n",
            "Tue Nov 04 01:57:26 PM 2025 AUC 0.925144486283982\n",
            "\n",
            "[mbo] 32: learning_rate=0.0103; feature_fraction=0.401; num_leaves=2031; min_data_in_leaf=5590; bagging_fraction=0.7 : y = 0.925 : 523.9 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 33 in the file bayesiana.RDATA.\n",
            "\n",
            "Tue Nov 04 01:58:12 PM 2025 AUC 0.926169924528786\n",
            "\n",
            "[mbo] 33: learning_rate=0.09; feature_fraction=0.4; num_leaves=20; min_data_in_leaf=119; bagging_fraction=0.592 : y = 0.926 : 45.2 secs : infill_ei\n",
            "\n",
            "Tue Nov 04 02:03:43 PM 2025 AUC 0.926141911648956\n",
            "\n",
            "[mbo] 34: learning_rate=0.01; feature_fraction=0.401; num_leaves=1235; min_data_in_leaf=28; bagging_fraction=0.404 : y = 0.926 : 330.5 secs : infill_ei\n",
            "\n",
            "Tue Nov 04 02:04:41 PM 2025 AUC 0.925011921747928\n",
            "\n",
            "[mbo] 35: learning_rate=0.0624; feature_fraction=0.401; num_leaves=2047; min_data_in_leaf=1435; bagging_fraction=0.348 : y = 0.925 : 58.3 secs : infill_ei\n",
            "\n",
            "Tue Nov 04 02:06:56 PM 2025 AUC 0.916792082057594\n",
            "\n",
            "[mbo] 36: learning_rate=0.118; feature_fraction=0.599; num_leaves=697; min_data_in_leaf=29; bagging_fraction=0.7 : y = 0.917 : 133.8 secs : infill_ei\n",
            "\n",
            "Tue Nov 04 02:14:53 PM 2025 AUC 0.923612171776916\n",
            "\n",
            "[mbo] 37: learning_rate=0.0101; feature_fraction=0.596; num_leaves=1715; min_data_in_leaf=7936; bagging_fraction=0.7 : y = 0.924 : 476.5 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 38 in the file bayesiana.RDATA.\n",
            "\n",
            "Tue Nov 04 02:15:43 PM 2025 AUC 0.924133684759903\n",
            "\n",
            "[mbo] 38: learning_rate=0.238; feature_fraction=0.469; num_leaves=2048; min_data_in_leaf=2572; bagging_fraction=0.7 : y = 0.924 : 49.2 secs : infill_ei\n",
            "\n",
            "Tue Nov 04 02:17:01 PM 2025 AUC 0.926312525544847\n",
            "\n",
            "[mbo] 39: learning_rate=0.0715; feature_fraction=0.6; num_leaves=84; min_data_in_leaf=3278; bagging_fraction=0.699 : y = 0.926 : 77.0 secs : infill_ei\n",
            "\n",
            "Tue Nov 04 02:20:33 PM 2025 AUC 0.929074377246905\n",
            "\n",
            "[mbo] 40: learning_rate=0.0101; feature_fraction=0.485; num_leaves=11; min_data_in_leaf=3; bagging_fraction=0.338 : y = 0.929 : 211.5 secs : infill_ei\n",
            "\n",
            "Tue Nov 04 02:21:33 PM 2025 AUC 0.924451085695612\n",
            "\n",
            "[mbo] 41: learning_rate=0.14; feature_fraction=0.4; num_leaves=9; min_data_in_leaf=2658; bagging_fraction=0.619 : y = 0.924 : 59.5 secs : infill_ei\n",
            "\n",
            "Tue Nov 04 02:26:34 PM 2025 AUC 0.930285252537496\n",
            "\n",
            "[mbo] 42: learning_rate=0.0101; feature_fraction=0.421; num_leaves=11; min_data_in_leaf=29; bagging_fraction=0.564 : y = 0.93 : 300.0 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 43 in the file bayesiana.RDATA.\n",
            "\n",
            "Tue Nov 04 02:28:46 PM 2025 AUC 0.927151721225255\n",
            "\n",
            "[mbo] 43: learning_rate=0.01; feature_fraction=0.57; num_leaves=2047; min_data_in_leaf=469; bagging_fraction=0.3 : y = 0.927 : 131.3 secs : infill_ei\n",
            "\n",
            "Tue Nov 04 02:30:24 PM 2025 AUC 0.926726160220279\n",
            "\n",
            "[mbo] 44: learning_rate=0.0653; feature_fraction=0.538; num_leaves=2048; min_data_in_leaf=2531; bagging_fraction=0.626 : y = 0.927 : 97.5 secs : infill_ei\n",
            "\n",
            "Tue Nov 04 02:35:22 PM 2025 AUC 0.927694051219746\n",
            "\n",
            "[mbo] 45: learning_rate=0.0101; feature_fraction=0.4; num_leaves=491; min_data_in_leaf=39; bagging_fraction=0.642 : y = 0.928 : 297.5 secs : infill_ei\n",
            "\n",
            "Tue Nov 04 02:36:36 PM 2025 AUC 0.887958639258179\n",
            "\n",
            "[mbo] 46: learning_rate=0.3; feature_fraction=0.518; num_leaves=1715; min_data_in_leaf=24; bagging_fraction=0.7 : y = 0.888 : 73.2 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 47 in the file bayesiana.RDATA.\n",
            "\n",
            "Tue Nov 04 02:37:19 PM 2025 AUC 0.924972953383421\n",
            "\n",
            "[mbo] 47: learning_rate=0.19; feature_fraction=0.599; num_leaves=1276; min_data_in_leaf=2506; bagging_fraction=0.699 : y = 0.925 : 43.3 secs : infill_ei\n",
            "\n",
            "Tue Nov 04 02:38:04 PM 2025 AUC 0.922917524668684\n",
            "\n",
            "[mbo] 48: learning_rate=0.293; feature_fraction=0.596; num_leaves=2038; min_data_in_leaf=4387; bagging_fraction=0.7 : y = 0.923 : 44.4 secs : infill_ei\n",
            "\n",
            "Tue Nov 04 02:45:56 PM 2025 AUC 0.924381348323455\n",
            "\n",
            "[mbo] 49: learning_rate=0.01; feature_fraction=0.598; num_leaves=200; min_data_in_leaf=5631; bagging_fraction=0.7 : y = 0.924 : 470.8 secs : infill_ei\n",
            "\n",
            "Tue Nov 04 02:51:53 PM 2025 AUC 0.931257153790528\n",
            "\n",
            "[mbo] 50: learning_rate=0.0101; feature_fraction=0.569; num_leaves=8; min_data_in_leaf=415; bagging_fraction=0.693 : y = 0.931 : 356.0 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 51 in the file bayesiana.RDATA.\n",
            "\n",
            "Tue Nov 04 02:53:51 PM 2025 AUC 0.924990484610758\n",
            "\n",
            "[mbo] 51: learning_rate=0.0582; feature_fraction=0.579; num_leaves=1920; min_data_in_leaf=4909; bagging_fraction=0.699 : y = 0.925 : 116.8 secs : infill_ei\n",
            "\n",
            "Tue Nov 04 02:54:30 PM 2025 AUC 0.923195675741364\n",
            "\n",
            "[mbo] 52: learning_rate=0.213; feature_fraction=0.576; num_leaves=2048; min_data_in_leaf=2702; bagging_fraction=0.549 : y = 0.923 : 38.5 secs : infill_ei\n",
            "\n",
            "Tue Nov 04 02:55:40 PM 2025 AUC 0.921666446922209\n",
            "\n",
            "[mbo] 53: learning_rate=0.214; feature_fraction=0.401; num_leaves=290; min_data_in_leaf=7993; bagging_fraction=0.7 : y = 0.922 : 69.9 secs : infill_ei\n",
            "\n",
            "Tue Nov 04 02:56:31 PM 2025 AUC 0.924959268844927\n",
            "\n",
            "[mbo] 54: learning_rate=0.206; feature_fraction=0.4; num_leaves=1133; min_data_in_leaf=2746; bagging_fraction=0.683 : y = 0.925 : 50.2 secs : infill_ei\n",
            "\n",
            "Tue Nov 04 02:58:39 PM 2025 AUC 0.925180565791066\n",
            "\n",
            "[mbo] 55: learning_rate=0.0639; feature_fraction=0.403; num_leaves=11; min_data_in_leaf=4666; bagging_fraction=0.699 : y = 0.925 : 127.9 secs : infill_ei\n",
            "\n",
            "Tue Nov 04 03:02:28 PM 2025 AUC 0.931283151122884\n",
            "\n",
            "[mbo] 56: learning_rate=0.0101; feature_fraction=0.439; num_leaves=11; min_data_in_leaf=271; bagging_fraction=0.491 : y = 0.931 : 228.1 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 57 in the file bayesiana.RDATA.\n",
            "\n",
            "Tue Nov 04 03:07:01 PM 2025 AUC 0.929397369953233\n",
            "\n",
            "[mbo] 57: learning_rate=0.0101; feature_fraction=0.411; num_leaves=9; min_data_in_leaf=571; bagging_fraction=0.483 : y = 0.929 : 271.9 secs : infill_ei\n",
            "\n",
            "Tue Nov 04 03:12:11 PM 2025 AUC 0.929015079471286\n",
            "\n",
            "[mbo] 58: learning_rate=0.01; feature_fraction=0.503; num_leaves=2047; min_data_in_leaf=1357; bagging_fraction=0.7 : y = 0.929 : 309.8 secs : infill_ei\n",
            "\n",
            "Tue Nov 04 03:12:53 PM 2025 AUC 0.922918073897844\n",
            "\n",
            "[mbo] 59: learning_rate=0.261; feature_fraction=0.6; num_leaves=624; min_data_in_leaf=3241; bagging_fraction=0.699 : y = 0.923 : 40.7 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 60 in the file bayesiana.RDATA.\n",
            "\n",
            "Tue Nov 04 03:17:03 PM 2025 AUC 0.929733330763648\n",
            "\n",
            "[mbo] 60: learning_rate=0.0101; feature_fraction=0.455; num_leaves=2046; min_data_in_leaf=295; bagging_fraction=0.503 : y = 0.93 : 249.6 secs : infill_ei\n",
            "\n",
            "Tue Nov 04 03:22:13 PM 2025 AUC 0.928086713435963\n",
            "\n",
            "[mbo] 61: learning_rate=0.01; feature_fraction=0.6; num_leaves=2048; min_data_in_leaf=1714; bagging_fraction=0.556 : y = 0.928 : 310.0 secs : infill_ei\n",
            "\n",
            "Tue Nov 04 03:30:24 PM 2025 AUC 0.924226640486651\n",
            "\n",
            "[mbo] 62: learning_rate=0.01; feature_fraction=0.535; num_leaves=1151; min_data_in_leaf=5711; bagging_fraction=0.7 : y = 0.924 : 489.6 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 63 in the file bayesiana.RDATA.\n",
            "\n",
            "Tue Nov 04 03:31:29 PM 2025 AUC 0.925698597931686\n",
            "\n",
            "[mbo] 63: learning_rate=0.0732; feature_fraction=0.478; num_leaves=2048; min_data_in_leaf=823; bagging_fraction=0.588 : y = 0.926 : 64.1 secs : infill_ei\n",
            "\n",
            "Tue Nov 04 03:32:19 PM 2025 AUC 0.92306132009732\n",
            "\n",
            "[mbo] 64: learning_rate=0.21; feature_fraction=0.403; num_leaves=2048; min_data_in_leaf=5042; bagging_fraction=0.7 : y = 0.923 : 49.6 secs : infill_ei\n",
            "\n",
            "Tue Nov 04 03:35:18 PM 2025 AUC 0.930830313086394\n",
            "\n",
            "[mbo] 65: learning_rate=0.0227; feature_fraction=0.429; num_leaves=9; min_data_in_leaf=269; bagging_fraction=0.698 : y = 0.931 : 178.4 secs : infill_ei\n",
            "\n",
            "Tue Nov 04 03:37:56 PM 2025 AUC 0.922968022802506\n",
            "\n",
            "[mbo] 66: learning_rate=0.0715; feature_fraction=0.501; num_leaves=2048; min_data_in_leaf=7977; bagging_fraction=0.7 : y = 0.923 : 156.9 secs : infill_ei\n",
            "\n",
            "Tue Nov 04 03:42:16 PM 2025 AUC 0.923990386988227\n",
            "\n",
            "[mbo] 67: learning_rate=0.041; feature_fraction=0.539; num_leaves=15; min_data_in_leaf=8000; bagging_fraction=0.7 : y = 0.924 : 259.0 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 68 in the file bayesiana.RDATA.\n",
            "\n",
            "Tue Nov 04 03:45:56 PM 2025 AUC 0.926325509781696\n",
            "\n",
            "[mbo] 68: learning_rate=0.0101; feature_fraction=0.456; num_leaves=2045; min_data_in_leaf=1606; bagging_fraction=0.314 : y = 0.926 : 218.5 secs : infill_ei\n",
            "\n",
            "Tue Nov 04 03:49:43 PM 2025 AUC 0.931003007830953\n",
            "\n",
            "[mbo] 69: learning_rate=0.01; feature_fraction=0.502; num_leaves=29; min_data_in_leaf=239; bagging_fraction=0.695 : y = 0.931 : 227.3 secs : infill_ei\n",
            "\n",
            "Tue Nov 04 03:52:50 PM 2025 AUC 0.930183030529392\n",
            "\n",
            "[mbo] 70: learning_rate=0.0102; feature_fraction=0.433; num_leaves=8; min_data_in_leaf=249; bagging_fraction=0.406 : y = 0.93 : 185.8 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 71 in the file bayesiana.RDATA.\n",
            "\n",
            "Tue Nov 04 03:57:24 PM 2025 AUC 0.93043752272953\n",
            "\n",
            "[mbo] 71: learning_rate=0.0103; feature_fraction=0.456; num_leaves=8; min_data_in_leaf=245; bagging_fraction=0.525 : y = 0.93 : 273.0 secs : infill_ei\n",
            "\n",
            "Tue Nov 04 03:58:37 PM 2025 AUC 0.922242517863921\n",
            "\n",
            "[mbo] 72: learning_rate=0.167; feature_fraction=0.401; num_leaves=21; min_data_in_leaf=5869; bagging_fraction=0.699 : y = 0.922 : 72.5 secs : infill_ei\n",
            "\n",
            "Tue Nov 04 03:59:14 PM 2025 AUC 0.911810303544333\n",
            "\n",
            "[mbo] 73: learning_rate=0.3; feature_fraction=0.431; num_leaves=2047; min_data_in_leaf=4739; bagging_fraction=0.3 : y = 0.912 : 36.3 secs : infill_ei\n",
            "\n",
            "Tue Nov 04 04:00:06 PM 2025 AUC 0.920542376684183\n",
            "\n",
            "[mbo] 74: learning_rate=0.297; feature_fraction=0.579; num_leaves=9; min_data_in_leaf=7994; bagging_fraction=0.691 : y = 0.921 : 51.0 secs : infill_ei\n",
            "\n",
            "Tue Nov 04 04:00:48 PM 2025 AUC 0.927834258039288\n",
            "\n",
            "[mbo] 75: learning_rate=0.0455; feature_fraction=0.405; num_leaves=8; min_data_in_leaf=158; bagging_fraction=0.3 : y = 0.928 : 41.5 secs : infill_ei\n",
            "\n",
            "Tue Nov 04 04:01:30 PM 2025 AUC 0.920812749330021\n",
            "\n",
            "[mbo] 76: learning_rate=0.3; feature_fraction=0.4; num_leaves=265; min_data_in_leaf=4432; bagging_fraction=0.7 : y = 0.921 : 41.8 secs : infill_ei\n",
            "\n",
            "Tue Nov 04 04:05:57 PM 2025 AUC 0.929575209756247\n",
            "\n",
            "[mbo] 77: learning_rate=0.01; feature_fraction=0.423; num_leaves=2044; min_data_in_leaf=357; bagging_fraction=0.696 : y = 0.93 : 265.4 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 78 in the file bayesiana.RDATA.\n",
            "\n",
            "Tue Nov 04 04:10:17 PM 2025 AUC 0.922596475409078\n",
            "\n",
            "[mbo] 78: learning_rate=0.01; feature_fraction=0.415; num_leaves=11; min_data_in_leaf=3035; bagging_fraction=0.301 : y = 0.923 : 259.4 secs : infill_ei\n",
            "\n",
            "Tue Nov 04 04:14:12 PM 2025 AUC 0.929403650633307\n",
            "\n",
            "[mbo] 79: learning_rate=0.0102; feature_fraction=0.599; num_leaves=1295; min_data_in_leaf=1116; bagging_fraction=0.7 : y = 0.929 : 234.3 secs : infill_ei\n",
            "\n",
            "Tue Nov 04 04:18:29 PM 2025 AUC 0.930038613069088\n",
            "\n",
            "[mbo] 80: learning_rate=0.0101; feature_fraction=0.411; num_leaves=1518; min_data_in_leaf=631; bagging_fraction=0.676 : y = 0.93 : 257.1 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 81 in the file bayesiana.RDATA.\n",
            "\n",
            "Tue Nov 04 04:23:20 PM 2025 AUC 0.927681314603485\n",
            "\n",
            "[mbo] 81: learning_rate=0.0101; feature_fraction=0.579; num_leaves=1581; min_data_in_leaf=1800; bagging_fraction=0.699 : y = 0.928 : 289.2 secs : infill_ei\n",
            "\n",
            "Tue Nov 04 04:24:28 PM 2025 AUC 0.927283427150769\n",
            "\n",
            "[mbo] 82: learning_rate=0.0786; feature_fraction=0.409; num_leaves=1157; min_data_in_leaf=1252; bagging_fraction=0.7 : y = 0.927 : 67.8 secs : infill_ei\n",
            "\n",
            "Tue Nov 04 04:31:45 PM 2025 AUC 0.924671662547622\n",
            "\n",
            "[mbo] 83: learning_rate=0.0101; feature_fraction=0.4; num_leaves=1928; min_data_in_leaf=4379; bagging_fraction=0.575 : y = 0.925 : 435.8 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 84 in the file bayesiana.RDATA.\n",
            "\n",
            "Tue Nov 04 04:32:51 PM 2025 AUC 0.924094922921109\n",
            "\n",
            "[mbo] 84: learning_rate=0.192; feature_fraction=0.519; num_leaves=10; min_data_in_leaf=1766; bagging_fraction=0.7 : y = 0.924 : 65.9 secs : infill_ei\n",
            "\n",
            "Tue Nov 04 04:36:50 PM 2025 AUC 0.921434356009682\n",
            "\n",
            "[mbo] 85: learning_rate=0.0174; feature_fraction=0.599; num_leaves=2046; min_data_in_leaf=6417; bagging_fraction=0.519 : y = 0.921 : 238.5 secs : infill_ei\n",
            "\n",
            "Tue Nov 04 04:37:38 PM 2025 AUC 0.921841602702135\n",
            "\n",
            "[mbo] 86: learning_rate=0.218; feature_fraction=0.6; num_leaves=11; min_data_in_leaf=5567; bagging_fraction=0.697 : y = 0.922 : 47.0 secs : infill_ei\n",
            "\n",
            "Tue Nov 04 04:38:08 PM 2025 AUC 0.92125564642321\n",
            "\n",
            "[mbo] 87: learning_rate=0.138; feature_fraction=0.599; num_leaves=1345; min_data_in_leaf=1331; bagging_fraction=0.3 : y = 0.921 : 28.9 secs : infill_ei\n",
            "\n",
            "Tue Nov 04 04:39:48 PM 2025 AUC 0.928357361452371\n",
            "\n",
            "[mbo] 88: learning_rate=0.0323; feature_fraction=0.436; num_leaves=1717; min_data_in_leaf=917; bagging_fraction=0.7 : y = 0.928 : 99.6 secs : infill_ei\n",
            "\n",
            "Tue Nov 04 04:41:04 PM 2025 AUC 0.920586544854313\n",
            "\n",
            "[mbo] 89: learning_rate=0.237; feature_fraction=0.592; num_leaves=2037; min_data_in_leaf=7995; bagging_fraction=0.7 : y = 0.921 : 75.0 secs : infill_ei\n",
            "\n",
            "Tue Nov 04 04:45:07 PM 2025 AUC 0.923834243295877\n",
            "\n",
            "[mbo] 90: learning_rate=0.0101; feature_fraction=0.6; num_leaves=9; min_data_in_leaf=4439; bagging_fraction=0.498 : y = 0.924 : 242.1 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 91 in the file bayesiana.RDATA.\n",
            "\n",
            "Tue Nov 04 04:45:46 PM 2025 AUC 0.918617658161494\n",
            "\n",
            "[mbo] 91: learning_rate=0.123; feature_fraction=0.402; num_leaves=2048; min_data_in_leaf=301; bagging_fraction=0.3 : y = 0.919 : 38.6 secs : infill_ei\n",
            "\n",
            "Tue Nov 04 04:47:06 PM 2025 AUC 0.924786094476762\n",
            "\n",
            "[mbo] 92: learning_rate=0.128; feature_fraction=0.557; num_leaves=2048; min_data_in_leaf=5953; bagging_fraction=0.7 : y = 0.925 : 78.9 secs : infill_ei\n",
            "\n",
            "Tue Nov 04 04:47:36 PM 2025 AUC 0.920470693781046\n",
            "\n",
            "[mbo] 93: learning_rate=0.3; feature_fraction=0.6; num_leaves=14; min_data_in_leaf=3287; bagging_fraction=0.49 : y = 0.92 : 29.3 secs : infill_ei\n",
            "\n",
            "Tue Nov 04 04:48:37 PM 2025 AUC 0.924244687731373\n",
            "\n",
            "[mbo] 94: learning_rate=0.0817; feature_fraction=0.6; num_leaves=409; min_data_in_leaf=2425; bagging_fraction=0.475 : y = 0.924 : 60.5 secs : infill_ei\n",
            "\n",
            "Tue Nov 04 04:52:15 PM 2025 AUC 0.930277786925878\n",
            "\n",
            "[mbo] 95: learning_rate=0.0101; feature_fraction=0.4; num_leaves=1734; min_data_in_leaf=333; bagging_fraction=0.609 : y = 0.93 : 216.8 secs : infill_ei\n",
            "\n",
            "Tue Nov 04 04:53:26 PM 2025 AUC 0.925836819212483\n",
            "\n",
            "[mbo] 96: learning_rate=0.0901; feature_fraction=0.404; num_leaves=522; min_data_in_leaf=2940; bagging_fraction=0.7 : y = 0.926 : 70.2 secs : infill_ei\n",
            "\n",
            "Tue Nov 04 04:57:13 PM 2025 AUC 0.927628146557687\n",
            "\n",
            "[mbo] 97: learning_rate=0.0102; feature_fraction=0.4; num_leaves=2039; min_data_in_leaf=1399; bagging_fraction=0.635 : y = 0.928 : 225.9 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 98 in the file bayesiana.RDATA.\n",
            "\n",
            "Tue Nov 04 04:59:51 PM 2025 AUC 0.923863972353065\n",
            "\n",
            "[mbo] 98: learning_rate=0.0513; feature_fraction=0.427; num_leaves=1798; min_data_in_leaf=6578; bagging_fraction=0.7 : y = 0.924 : 156.8 secs : infill_ei\n",
            "\n",
            "Tue Nov 04 05:03:23 PM 2025 AUC 0.92744898784579\n",
            "\n",
            "[mbo] 99: learning_rate=0.01; feature_fraction=0.543; num_leaves=1708; min_data_in_leaf=1185; bagging_fraction=0.5 : y = 0.927 : 211.4 secs : infill_ei\n",
            "\n",
            "Tue Nov 04 05:04:32 PM 2025 AUC 0.925586815773261\n",
            "\n",
            "[mbo] 100: learning_rate=0.121; feature_fraction=0.593; num_leaves=2048; min_data_in_leaf=3921; bagging_fraction=0.7 : y = 0.926 : 67.6 secs : infill_ei\n",
            "\n",
            "Saved the final state in the file bayesiana.RDATA\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "tb_bayesiana <- as.data.table(bayesiana_salida$opt.path)\n",
        "colnames( tb_bayesiana)"
      ],
      "metadata": {
        "id": "ssk5nnMk6INK",
        "outputId": "78e4b5b1-67c9-42cc-9c20-89ca42ca5b93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style>\n",
              ".list-inline {list-style: none; margin:0; padding: 0}\n",
              ".list-inline>li {display: inline-block}\n",
              ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
              "</style>\n",
              "<ol class=list-inline><li>'learning_rate'</li><li>'feature_fraction'</li><li>'num_leaves'</li><li>'min_data_in_leaf'</li><li>'bagging_fraction'</li><li>'y'</li><li>'dob'</li><li>'eol'</li><li>'error.message'</li><li>'exec.time'</li><li>'ei'</li><li>'error.model'</li><li>'train.time'</li><li>'prop.type'</li><li>'propose.time'</li><li>'se'</li><li>'mean'</li></ol>\n"
            ],
            "text/markdown": "1. 'learning_rate'\n2. 'feature_fraction'\n3. 'num_leaves'\n4. 'min_data_in_leaf'\n5. 'bagging_fraction'\n6. 'y'\n7. 'dob'\n8. 'eol'\n9. 'error.message'\n10. 'exec.time'\n11. 'ei'\n12. 'error.model'\n13. 'train.time'\n14. 'prop.type'\n15. 'propose.time'\n16. 'se'\n17. 'mean'\n\n\n",
            "text/latex": "\\begin{enumerate*}\n\\item 'learning\\_rate'\n\\item 'feature\\_fraction'\n\\item 'num\\_leaves'\n\\item 'min\\_data\\_in\\_leaf'\n\\item 'bagging\\_fraction'\n\\item 'y'\n\\item 'dob'\n\\item 'eol'\n\\item 'error.message'\n\\item 'exec.time'\n\\item 'ei'\n\\item 'error.model'\n\\item 'train.time'\n\\item 'prop.type'\n\\item 'propose.time'\n\\item 'se'\n\\item 'mean'\n\\end{enumerate*}\n",
            "text/plain": [
              " [1] \"learning_rate\"    \"feature_fraction\" \"num_leaves\"       \"min_data_in_leaf\"\n",
              " [5] \"bagging_fraction\" \"y\"                \"dob\"              \"eol\"             \n",
              " [9] \"error.message\"    \"exec.time\"        \"ei\"               \"error.model\"     \n",
              "[13] \"train.time\"       \"prop.type\"        \"propose.time\"     \"se\"              \n",
              "[17] \"mean\"            "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# almaceno los resultados de la Bayesian Optimization\n",
        "# y capturo los mejores hiperparametros encontrados\n",
        "\n",
        "tb_bayesiana <- as.data.table(bayesiana_salida$opt.path)\n",
        "\n",
        "tb_bayesiana[, iter := .I]\n",
        "\n",
        "# ordeno en forma descendente por AUC = y\n",
        "setorder(tb_bayesiana, -y)\n",
        "\n",
        "# grabo para eventualmente poder utilizarlos en OTRA corrida\n",
        "fwrite( tb_bayesiana,\n",
        "  file= \"BO_log.txt\",\n",
        "  sep= \"\\t\"\n",
        ")\n",
        "\n",
        "# los mejores hiperparámetros son los que quedaron en el registro 1 de la tabla\n",
        "PARAM$out$lgbm$mejores_hiperparametros <- tb_bayesiana[\n",
        "  1, # el primero es el de mejor AUC\n",
        "  setdiff(colnames(tb_bayesiana),\n",
        "    c(\"y\",\"dob\",\"eol\",\"error.message\",\"exec.time\",\"ei\",\"error.model\",\n",
        "      \"train.time\",\"prop.type\",\"propose.time\",\"se\",\"mean\",\"iter\")),\n",
        "  with= FALSE\n",
        "]\n",
        "\n",
        "\n",
        "PARAM$out$lgbm$y <- tb_bayesiana[1, y]\n"
      ],
      "metadata": {
        "id": "u4zq-vknhjGc"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "write_yaml( PARAM, file=\"PARAM.yml\")"
      ],
      "metadata": {
        "id": "E8v2eA427N8e"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(PARAM$out$lgbm$mejores_hiperparametros)\n",
        "print(PARAM$out$lgbm$y)"
      ],
      "metadata": {
        "id": "iBTWexVU7PGC",
        "outputId": "c527bb49-2ce0-4cd6-ed32-50985e1f7805",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NULL\n",
            "NULL\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.3  Produccion"
      ],
      "metadata": {
        "id": "TKsVZmAnhwX-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Final Training\n",
        "Construyo el modelo final, que es uno solo, no hace ningun tipo de particion < training, validation, testing>]"
      ],
      "metadata": {
        "id": "RQ_C33Tr5B_9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "setwd(\"/content/buckets/b1/exp\")\n",
        "experimento <- paste0(\"exp\", PARAM$experimento)\n",
        "dir.create(experimento, showWarnings= FALSE)\n",
        "setwd( paste0(\"/content/buckets/b1/exp/\", experimento ))"
      ],
      "metadata": {
        "id": "eDqfyA14hzwv"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Final Training Dataset\n",
        "\n",
        "Aqui esta la gran decision de en qué meses hago el Final Training\n",
        "<br> debo utilizar los mejores hiperparámetros que encontré en la optimización bayesiana"
      ],
      "metadata": {
        "id": "8qFmFivf5Iet"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# clase01\n",
        "dataset[, clase01 := ifelse(clase_ternaria %in% c(\"BAJA+1\", \"BAJA+2\"), 1L, 0L)]"
      ],
      "metadata": {
        "id": "lg5WVZncvc7H"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_train <- dataset[foto_mes %in% c(202107)]"
      ],
      "metadata": {
        "id": "yc9QzXREv0xf"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dejo los datos en el formato que necesita LightGBM\n",
        "\n",
        "dtrain <- lgb.Dataset(\n",
        "  data= data.matrix(dataset_train[, campos_buenos, with= FALSE]),\n",
        "  label= dataset_train[, clase01]\n",
        ")"
      ],
      "metadata": {
        "id": "thjdqEBLuvNt"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Final Training Hyperparameters"
      ],
      "metadata": {
        "id": "VNUa-WSz5Oqu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param_final <- modifyList(PARAM$lgbm$param_fijos,\n",
        "  PARAM$out$lgbm$mejores_hiperparametros)\n",
        "\n",
        "param_final"
      ],
      "metadata": {
        "id": "FgCcvBfEwImu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Training\n",
        "Genero el modelo final, siempre sobre TODOS los datos de  final_train, sin hacer ningun tipo de undersampling de la clase mayoritaria"
      ],
      "metadata": {
        "id": "TZIYn4l95TBH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# este punto es muy SUTIL  y será revisado en la Clase 05\n",
        "param_final$early_stopping_rounds= 0\n",
        "param_normalizado <- copy(param_final)\n",
        "param_normalizado$min_data_in_leaf <-  round(param_final$min_data_in_leaf / PARAM$trainingstrategy$undersampling)"
      ],
      "metadata": {
        "id": "vPLsd4mMRe4u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  # entreno LightGBM\n",
        "\n",
        "  modelo_final <- lgb.train(\n",
        "    data= dtrain,\n",
        "    param= param_normalizado\n",
        "  )"
      ],
      "metadata": {
        "id": "WRI_-taRwOXO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ahora imprimo la importancia de variables\n",
        "\n",
        "tb_importancia <- as.data.table(lgb.importance(modelo_final))\n",
        "archivo_importancia <- \"impo.txt\"\n",
        "\n",
        "fwrite(tb_importancia,\n",
        "  file= archivo_importancia,\n",
        "  sep= \"\\t\"\n",
        ")"
      ],
      "metadata": {
        "id": "_bkhnCvj0g3Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# grabo a disco el modelo en un formato para seres humanos ... ponele ...\n",
        "\n",
        "lgb.save(modelo_final, \"modelo.txt\" )"
      ],
      "metadata": {
        "id": "lZ3sLmbh0kFj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Scoring"
      ],
      "metadata": {
        "id": "VEtp2--t5Ymg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aplico el modelo final a los datos del futuro"
      ],
      "metadata": {
        "id": "hI5008Mj5ZdI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# aplico el modelo a los datos sin clase\n",
        "dfuture <- dataset[foto_mes == 202109]\n",
        "\n",
        "# aplico el modelo a los datos nuevos\n",
        "prediccion <- predict(\n",
        "  modelo_final,\n",
        "  data.matrix(dfuture[, campos_buenos, with= FALSE])\n",
        ")"
      ],
      "metadata": {
        "id": "PimBY3N_0ryP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Tabla Prediccion"
      ],
      "metadata": {
        "id": "D26rNRh55gpw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# tabla de prediccion\n",
        "\n",
        "tb_prediccion <- dfuture[, list(numero_de_cliente)]\n",
        "tb_prediccion[, prob := prediccion ]\n",
        "\n",
        "# grabo las probabilidad del modelo\n",
        "fwrite(tb_prediccion,\n",
        "  file= \"prediccion.txt\",\n",
        "  sep= \"\\t\"\n",
        ")"
      ],
      "metadata": {
        "id": "RJwg7LHd11yu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kaggle Competition Submit"
      ],
      "metadata": {
        "id": "jOt4eG_55ltv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# genero archivos con los  \"envios\" mejores\n",
        "# suba TODOS los archivos a Kaggle\n",
        "\n",
        "# ordeno por probabilidad descendente\n",
        "setorder(tb_prediccion, -prob)\n",
        "\n",
        "dir.create(\"kaggle\")\n",
        "\n",
        "for (envios in PARAM$kaggle$cortes) {\n",
        "\n",
        "  tb_prediccion[, Predicted := 0L] # seteo inicial a 0\n",
        "  tb_prediccion[1:envios, Predicted := 1L] # marclo los primeros\n",
        "\n",
        "  archivo_kaggle <- paste0(\"./kaggle/KA\", PARAM$experimento, \"_\", envios, \".csv\")\n",
        "\n",
        "  # grabo el archivo\n",
        "  fwrite(tb_prediccion[, list(numero_de_cliente, Predicted)],\n",
        "    file= archivo_kaggle,\n",
        "    sep= \",\"\n",
        "  )\n",
        "\n",
        "  # subida a Kaggle, armo la linea de comando\n",
        "  comando <- \"kaggle competitions submit\"\n",
        "  competencia <- paste(\"-c\", PARAM$kaggle$competencia)\n",
        "  arch <- paste( \"-f\", archivo_kaggle)\n",
        "\n",
        "  mensaje <- paste0(\"-m 'envios=\", envios,\n",
        "  \"  semilla=\", PARAM$semilla_primigenia,\n",
        "    \"'\" )\n",
        "\n",
        "  linea <- paste( comando, competencia, arch, mensaje)\n",
        "\n",
        "  salida <- system(linea, intern=TRUE) # el submit a Kaggle\n",
        "  cat(salida, \"\\n\")\n",
        "  Sys.sleep(45)\n",
        "}"
      ],
      "metadata": {
        "id": "gWW3tatE12je"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "write_yaml( PARAM, file=\"PARAM.yml\")"
      ],
      "metadata": {
        "id": "B9tB2X4439Hg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "format(Sys.time(), \"%a %b %d %X %Y\")"
      ],
      "metadata": {
        "id": "9zA_W25c15DP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finalmente usted deberá cargar el resultado de su corrida en la Google Sheet Colaborativa,  hoja **TareaHogar-05**\n",
        "<br> Siéntase libre de agregar las columnas que hagan falta a la planilla"
      ],
      "metadata": {
        "id": "UdVZucdLHzZ0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Seguramente usted realice varias corridas de este script con distintos conjuntos de hiperparámetros, siempre cambiandole el nombre al script  y también cambiando el nombre del experimento,  deberá TODAS esas corridas en distintas lineas de la  Google Sheet Colaborativa, hoja **TareaHogar-05**"
      ],
      "metadata": {
        "id": "5MB_67DmDTh0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Siéntase libre de agregar columnas a la hoja **TareaHogar-05**  en caso de ser necesario."
      ],
      "metadata": {
        "id": "OnRUS_PhFI1Z"
      }
    }
  ]
}